ADHD Digital Phenotype Analysis Pipeline - Technical Manual

(Version 2.0 - Based on sheet-based groups and metadata file)

ğŸ“Š Current Pipeline Structure

This document describes the exact flow orchestrated by main_pipeline.py.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 0: DATA LOADING                        â”‚
â”‚                  (data_loader.py, config.py)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Load Fitbit Data (config.FITBIT_FILE)                      â”‚
â”‚    - Read ONLY specified sheets (config.SHEETS_TO_LOAD):      â”‚
â”‚      'NC_Controls', 'ADHD_Unmedicated', 'ADHD_Stimulants'       â”‚
â”‚    - Assign analysis_group (0, 1, 2) based on sheet name      â”‚
â”‚    - Combine sheets into single DataFrame                       â”‚
â”‚                                                                 â”‚
â”‚ 2. Load Metadata (config.METADATA_FILE)                       â”‚
â”‚    - Extract covariates (config.COVARIATES): 'sex', 'interview_age'â”‚
â”‚    - Keep only unique subjects                                  â”‚
â”‚                                                                 â”‚
â”‚ 3. Merge Datasets                                              â”‚
â”‚    - Left join Fitbit â† Metadata on 'subjectkey'              â”‚
â”‚    - Check covariate coverage (logs show ~52.5%)               â”‚
â”‚                                                                 â”‚
â”‚ 4. Prepare Covariates                                          â”‚
â”‚    - Convert categorical â†’ dummy variables ('sex' â†’ 'sex_M')   â”‚
â”‚    - Create final covariate column list                        â”‚
â”‚                                                                 â”‚
â”‚ 5. Convert Features to Numeric (CRITICAL FIX)                  â”‚
â”‚    - pd.to_numeric() all 125 Fitbit features                   â”‚
â”‚    - Coerce errors ('#N/A', 'NULL') to NaN                     â”‚
â”‚                                                                 â”‚
â”‚ 6. Handle Missing Values (utils.py)                            â”‚
â”‚    - Drop rows with missing features OR covariates             â”‚
â”‚    - Result: 2,491 â†’ 1,309 subjects (52.5% retained)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        PHASE 1: RESIDUALIZATION (Covariate Adjustment)          â”‚
â”‚                   (residualization.py)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ For each of 125 Fitbit features:                              â”‚
â”‚                                                                 â”‚
â”‚ 1. Isolate Healthy Controls (n=1,171)                         â”‚
â”‚                                                                 â”‚
â”‚ 2. Fit OLS Regression (controls only):                        â”‚
â”‚    feature ~ sex_M + interview_age + intercept                â”‚
â”‚                                                                 â”‚
â”‚ 3. Predict for ALL subjects (n=1,309)                         â”‚
â”‚                                                                 â”‚
â”‚ 4. Calculate Residuals:                                       â”‚
â”‚    residual = actual_value - predicted_value                   â”‚
â”‚                                                                 â”‚
â”‚ 5. Store residualized feature (demographic effects removed)    â”‚
â”‚                                                                 â”‚
â”‚ Outputs:                                                        â”‚
â”‚ - residualized_data.csv (1,309 Ã— 127 columns)                 â”‚
â”‚ - residualization_statistics.csv (RÂ², p-values per feature)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PHASE 1.5: UNIVARIATE STATISTICAL TESTS                 â”‚
â”‚                 (univariate_tests.py)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ For each feature Ã— comparison pair:                            â”‚
â”‚                                                                 â”‚
â”‚ 1. Extract groups (e.g., Controls vs Unmedicated)             â”‚
â”‚                                                                 â”‚
â”‚ 2. Calculate Statistics:                                       â”‚
â”‚    - Group means, SDs, medians                                 â”‚
â”‚    - Independent t-test â†’ t-stat, p-value                     â”‚
â”‚    - Mann-Whitney U test â†’ U-stat, p-value                    â”‚
â”‚    - Cohen's d effect size                                     â”‚
â”‚                                                                 â”‚
â”‚ 3. FDR Correction (Benjamini-Hochberg):                       â”‚
â”‚    - Convert p-values â†’ q-values                              â”‚
â”‚    - Flag significant features (q < 0.05)                     â”‚
â”‚                                                                 â”‚
â”‚ Outputs:                                                        â”‚
â”‚ - univariate_tests_[comparison].csv (125 rows Ã— ~20 cols)     â”‚
â”‚ - effect_size_summary.csv (significant features only)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 2: PREDICTIVE MODELING                       â”‚
â”‚                (predictive_models.py)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ For each comparison pair (3 comparisons):                      â”‚
â”‚                                                                 â”‚
â”‚ 1. Prepare Binary Classification Data:                        â”‚
â”‚    - Filter to 2 groups                                        â”‚
â”‚    - Create binary labels (0/1)                               â”‚
â”‚    - Remove zero-variance features                            â”‚
â”‚                                                                 â”‚
â”‚ 2. Train/Test Split (70/30, stratified):                      â”‚
â”‚    - Ensures balanced class representation                     â”‚
â”‚                                                                 â”‚
â”‚ 3. Model A: Elastic Net Logistic Regression                   â”‚
â”‚    - L1 + L2 regularization (l1_ratio=0.5)                   â”‚
â”‚    - Class weights balanced (handles 1,171 vs 74 vs 64)      â”‚
â”‚    - 5-fold cross-validation                                   â”‚
â”‚    - Output: Coefficients (feature importance)                 â”‚
â”‚                                                                 â”‚
â”‚ 4. Model B: Regularized Random Forest                         â”‚
â”‚    - max_depth=5, min_samples_leaf=5 (prevent overfitting)   â”‚
â”‚    - max_features='sqrt' (~11 features per split)             â”‚
â”‚    - Out-of-bag error tracking                                 â”‚
â”‚    - Output: Feature importances                               â”‚
â”‚                                                                 â”‚
â”‚ 5. Evaluation Metrics:                                        â”‚
â”‚    - Accuracy, ROC-AUC, Precision, Recall, F1                 â”‚
â”‚    - Confusion matrix, ROC curves, Calibration analysis       â”‚
â”‚                                                                 â”‚
â”‚ Outputs:                                                        â”‚
â”‚ - model_[comparison]_results.png (8-panel visualization)      â”‚
â”‚ - lr_coefficients_[comparison].csv                            â”‚
â”‚ - rf_importances_[comparison].csv                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PHASE 3: PCA VISUALIZATION                             â”‚
â”‚                  (visualization.py)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Standardize Features (StandardScaler)                      â”‚
â”‚                                                                 â”‚
â”‚ 2. Fit PCA (10 components for scree, 2-3 for visualization)   â”‚
â”‚                                                                 â”‚
â”‚ 3. Statistical Testing:                                        â”‚
â”‚    - ANOVA on PC1, PC2 by group                               â”‚
â”‚    - Test if groups separate in PCA space                     â”‚
â”‚                                                                 â”‚
â”‚ 4. Visualizations:                                            â”‚
â”‚    - Scree plot (explained variance)                          â”‚
â”‚    - 2D scatter (PC1 vs PC2, colored by group)               â”‚
â”‚    - 3D scatter (PC1 vs PC2 vs PC3)                          â”‚
â”‚    - Loading heatmap (top 30 features)                        â”‚
â”‚                                                                 â”‚
â”‚ Outputs:                                                        â”‚
â”‚ - pca_2d_plot.png, pca_3d_plot.png, pca_scree_plot.png        â”‚
â”‚ - pca_loadings.png                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FINAL: REPORTS & SUMMARY                          â”‚
â”‚                      (utils.py)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - summary_report.txt (human-readable)                         â”‚
â”‚ - pipeline_results.json (machine-readable)                    â”‚
â”‚ - pipeline.log (detailed execution trace)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ğŸ”„ Data Flow & Sample Sizes

This flow traces the number of subjects through the pipeline.

Group

Raw (From Excel Sheets)

After Covariate Merge

After Cleaning (dropna)

NC Controls

2,238

2,238

1,171 (52.3%)

ADHD Unmedicated

143

143

74 (51.7%)

ADHD Stimulants

110

110

64 (58.2%)

TOTAL

2,491

2,491

1,309 (52.5%)

Data Flow Summary:
fitbit_data.xlsx (3 sheets)
â†“ [load_fitbit_data()]
2,491 rows Ã— ~130 columns
â†“ [merge with metadata]
2,491 rows Ã— ~136 columns (added sex, age)
â†“ [convert to numeric + handle missing]
1,309 rows Ã— 136 columns (52.5% retained)
â†“ [residualize]
1,309 rows Ã— 127 columns (residualized features)
â†“ [univariate tests]
375 statistical comparisons (125 features Ã— 3 pairs)
â†“ [train models]
6 models (2 algorithms Ã— 3 comparisons)
â†“ [PCA]
1,309 points in 10D â†’ 2D/3D projections

âš ï¸ Critical Issue Identified (and Fixed)

Problem: Data Type Mismatch

Symptom: OLS regression in Phase 1 fails with "Pandas data cast to numpy dtype of object".

Root Cause: Excel import with mixed content (numbers + text like '#N/A', 'NULL', empty strings) causes feature columns to be stored as dtype('O') (object/string) instead of float64.

Solution Applied (in data_loader.py): A loop was added in get_available_features() to force-convert all feature columns to numeric type before any analysis.

# In data_loader.py -> get_available_features():
for feature in available_features:
    df[feature] = pd.to_numeric(df[feature], errors='coerce')
    # Converts: '123.4' â†’ 123.4, '#N/A' â†’ NaN, 'NULL' â†’ NaN


This fix is essential and allows the pipeline to run end-to-end.

ğŸ”§ Key Configuration Parameters (config.py)

Covariates

# Primary covariates used for residualization
COVARIATES = ['sex', 'interview_age']  
# Note: family_income, parent_grade, etc. are NOT used in this config
# Coverage: 52.5% (1,309/2,491 subjects)


Model Parameters (Tuned for small N)

# Elastic Net Logistic Regression (handles correlated features)
penalty='elasticnet', l1_ratio=0.5, C=1.0, class_weight='balanced'

# Random Forest (conservative to prevent overfitting)
max_depth=5, min_samples_leaf=5, max_features='sqrt', oob_score=True


Comparison Pairs

Control (n=1,171) vs Unmedicated (n=74)

Control (n=1,171) vs Stimulant (n=64)

Unmedicated (n=74) vs Stimulant (n=64)

ğŸ“ˆ Interpretation Guide

Residualization RÂ² (residualization_statistics.csv)

RÂ² = 0.0: Covariate has no effect (or feature is categorical).

RÂ² = 0.1-0.3: Moderate demographic influence (expected).

RÂ² > 0.4: Strong age/sex effect (e.g., resting heart rate).

Effect Sizes (Cohen's d) (univariate_tests_...csv)

|d| < 0.2: Negligible

|d| = 0.2-0.5: Small

|d| = 0.5-0.8: Medium

|d| > 0.8: Large

Model Performance (model_..._results.png)

AUC = 0.50: No better than chance.

AUC = 0.70: Acceptable discrimination.

AUC = 0.80: Excellent discrimination.

AUC = 0.90+: Outstanding (rare in behavioral data).

PCA Interpretation (pca_2d_plot.png)

Clear separation: Groups have distinct phenotypes.

Overlap: Shared physiology, subtle differences.

No separation: Differences are multivariate, not in dominant axes.